\chapter{Design and Implementation}
\label{cha:impl}

\section{Outline}
The basic outline of the proposed \ac{SLAM} algorithm is shown in figure \ref{SLAM_Outline}. Firstly, While a new frame comes, a common bilateral filter will smoothen the depth map, some noise and large depth measurements will be removed. The comparison of the depth maps before and after the bilateral filter is shown in figure \ref{BF_comparison}.
\begin{figure}[thb]
    \centering
    \includegraphics[width=1\textwidth]{images/SLAM_Outline.pdf}
    \caption[The outline of proposed SLAM algorithm]{The outline of the proposed SLAM algorithm}\label{SLAM_Outline}
\end{figure}

Secondly, the pose of the current frame will be estimated via the \ac{ICP} method. Then, the keyframe selection method will be executed to determine whether the frame is selected as a keyframe. The following subsection \ref{K_S_M} will introduce several keyframe selection methods.

Thirdly, if the current frame is selected as a new keyframe, the Loop Closure Detection will be conducted, which will be introduced in section \ref{Loop_Detection}. The basic idea of Loop Closure Detection is to compare the current frame with all other keyframes and determine whether we have returned to the starting point or the previous position. If a close-loop is detected, the message "A and B are the same point" will be given to the Back End. 

Finally, all the information will be given to the Back End to conduct the Direct BA method. 

There are three main improvements as shown in the red parts of figure \ref{SLAM_Outline}. The detailed implementation of these parts will be shown later.

\section{Data Representation}
\label{Data_Representation}

The $kth$ keyframe is defined by its RGB-D frame and the 7 \ac{DOF} $\boldsymbol{\xi}_k$ to define the pose of the camera. $\boldsymbol{\xi}_k$ is given by
\begin{equation}
    \boldsymbol{\xi}_k=(t_x,\; t_y,\; t_z,\; q_x,\; q_y,\; q_z,\; q_w)^T
\end{equation}

For simplicity of expression,
\begin{equation}
    \rho_k=(t_x,\; t_y,\; t_z)^T
\end{equation}
\begin{equation}
    \phi_k=(q_x,\; q_y,\; q_z,\; q_w)^T
\end{equation}
\begin{equation}
    \boldsymbol{\xi_k}=\left[\begin{array}{l}
        \rho_k \\
        \phi_k
        \end{array}\right]
\end{equation}

where the first three numbers represent the translation vector $\rho_k$, and the last four numbers represent the rotation vector $\phi_k$ in the form of a quaternion.
\begin{figure}[thb]
    \centering
    \includegraphics[width=1\textwidth]{images/Matrices.pdf}
    \caption[The matrices of the gray image and the depth map]{The matrices of the gray image and the depth map.}\label{Matrices}
\end{figure}

The raw RGB-D images comprise the 3-channel color pictures and 1-channel depth maps. The size of each variable of the color image is 8bit, and each variable of the depth map is 16bit. In the preprocessing stage, according to equation \ref{RGB2GRAY}, the 3-channel color image will be converted into the 1-channel gray image. 
\begin{equation}
    \boldsymbol{I}_{ij}=0.2989 * R_{ij} + 0.5870 * G_{ij} + 0.1140 * B_{ij}
    \label{RGB2GRAY}
\end{equation}

The matrix $\boldsymbol{I_k}$ and $\boldsymbol{Z_k}$ contain the gray image and the depth map of each keyframe. Take the ETH3D dataset as an example, these two matrices are given in figure \ref{Matrices}.

\section{The bilateral filter}

As we mentioned in subsection \ref{3_The_Bilateral_Filter}, while a new frame comes, a common bilateral filter will smoothen the depth map first. The bilateral filter will construct a convolution kernel based on the adjacent pixels for every pixel. The convolution kernel of the ($r,c$)th pixel $Kernel(h,w)$ is given by
\begin{equation}
    \begin{aligned}
    Kernel(h,w)&=Kernel_{closeness}(h,w)\cdot Kernel_{similarity}(h,w)\\
    &=\exp \left(-\frac{\left(h-\frac{winH-1}{2}\right)^{2}+\left(w-\frac{winW-1}{2}\right)^{2}}{2 \sigma_{1}^{2}}\right)\\
    & \quad \cdot \exp \left(-\frac{\| \boldsymbol{I}(r, c)-\boldsymbol{I}\left(r+\left(h-\frac{winH-1}{2}\right), c+\left(w-\frac{winW-1}{2}\right) \|^{2}\right.}{2 \sigma_{2}^{2}}\right)
    \end{aligned}
    \label{Equ_Bilateral_Filter}
\end{equation}

where $Kernel_{closeness}(h,w)$ is a gauss matrix relative to the distance between $(h,w)$ and kernel center, $Kernel_{similarity}(h,w)$ is a gauss matrix relative to the similarity between $(h,w)$ and $(r,c)$, $0<h<winH$, $0<w<winW$, $winH$ represents the hight of the kernel, $winW$ represents the width of the kernel, $\sigma_{1}$ and $\sigma_2$ represent the standard deviation of two gauss matrices.
\begin{figure}[thb]
    \centering
    \includegraphics[width=1\textwidth]{images/D_S_D.pdf}
    \caption[The comparison of the different standard deviation in bilateral filter]{The comparison of the different standard deviation in the bilateral filter. The top image is the original, and the bottom images are the smoothed depth maps. The larger the standard deviation $\sigma$, the smoother the depth map and the less noise.}\label{D_S_D_F}
\end{figure}

The different standard deviation $\sigma$ of the bilateral filter has different effects on the results as shown in figure \ref{D_S_D_F}. The larger the standard deviation $\sigma$, the smoother the depth map and the less noise. Therefore, several experiments will be conducted, the best standard deviation $\sigma$ will be determined.

\section{Keyframe Selection Method}
\label{K_S_M}

In order to find the best keyframe selection method for the real-time SLAM system in the indoor environment, three different methods will be tested, Constant Number of Interval Frames, Euclidean Distance and the proposed method, mixed distance.

\subsection{Constant Number of Interval Frames}
A simple and popular keyframe selection method is to select keyframes after a constant number of interval frames. The advantage of this method is that the computation is small, but the disadvantage is also very obvious, that is, poor adaptability. If the moving speed is slow, it is easy to generate too close keyframes, which wastes computing resources. If the movement speed is too fast, large errors will occur. For handheld mobile devices, this method is obviously not good enough. We will test different constant numbers of interval frames and find compare the results, the best one will be set as the maximum number of interval frames $K_{max}$ in further experiments.

\subsection{Euclidean Distance}
In mathematics, the Euclidean distance or Euclidean metric is the ordinary straight-line distance between two points in Euclidean space. With this distance, Euclidean space becomes a metric space. The associated norm is called the Euclidean norm. Older literature refers to the metric as the Pythagorean metric \parencite{EuclideanDistance}. The Euclidean distance is applied to determine the distance between two frames in this keyframe selection method, $d$, it is given by equation \ref{Euclidean_Distance}.
\begin{equation}
    d=\left\|\boldsymbol{\xi}_{1}, \; \boldsymbol{\xi}_{2}\right\|=\sqrt{\sum_{i=1}^{7}\left(\boldsymbol{\xi}_{1,i}-\boldsymbol{\xi}_{2,i}\right)^{2}}
    \label{Euclidean_Distance}
\end{equation}

In order to prevent the disadvantages of the Constant Number of Interval Frames method, in this keyframe selection method, once the Euclidean distance between the current frame and last keyframe is large than the maximum distance $D_{Euc}$ or $K_{max}$ frames have passed from the last keyframe, set the current frame as a new keyframe.

\subsection{Mixed Distance}
\label{Subsection_Mixed_Distance}
There are two different parts in the camera poses' vector $\boldsymbol{\xi}$ as we mentioned in section \ref{Data_Representation}. And the impacts of these two parts are different, SLAM systems are more sensitive to rotation movement. Therefore, in this project, two coefficients for translation and rotation are proposed in a new keyframe selection method.

A new mixed Euclidean distance is proposed which combines translation and rotation movement. This mixed Euclidean distance is given by equation 
\begin{equation}
    \begin{aligned}
        d_{\text {mixed}} &=\mu_{t}\left\|\boldsymbol{t}_{1}, \; \boldsymbol{t}_{2}\right\|+\mu_{q}\left\|\boldsymbol{q}_{1} \; \boldsymbol{q}_{2}\right\| \\
        &=\mu_{t} \sqrt{\sum_{i=1}^{3}\left(\boldsymbol{\xi}_{1_{i}}-\boldsymbol{\xi}_{2_{i}}\right)^{2}}+\mu_{q} \sqrt{\sum_{i=4}^{7}\left(\boldsymbol{\xi}_{1_{i}}-\boldsymbol{\xi}_{2_{i}}\right)^{2}}
    \end{aligned}
    \label{New_Euclidean_Distance}
\end{equation}

where $\mu_{t}$ and $\mu_{q}$ represent the coefficients of translation and rotation movement. Several experiments will be conducted, and the best values of these coefficients will be determined.

\section{Robust Kernel Function}
In order to let the optimization algorithm distinguish the outliers, the Tukey's biweight robust loss function is applied to errors before the optimization. Its equation is given by equation \ref{Tukey}, and its plot is as shown in figure \ref{Tukey_Plot}. Now, the cost function \ref{New_Cost_Function} is changed to equation \ref{Tukey_Cost_Function}.
\begin{equation}
    Tukey(e)=\left\{\begin{array}{ll}
        e\left(1-\frac{e^{2}}{c^{2}}\right)^{2} & \text { for }|e|<c \\
        0 & \text { for }|e|>c
        \end{array}\right.\label{Tukey}
\end{equation}
\begin{figure}[thb]
    \centering
    \includegraphics[width=0.7\textwidth]{images/Tukey.pdf}
    \caption[The plot of the Tukey's biweight robust loss function.]{The plot of the Tukey's biweight robust loss function.}\label{Tukey_Plot}
\end{figure}
\begin{equation}
    \|f(\boldsymbol{x}+\Delta \boldsymbol{x})\|^{2}=\left\|Tukey(\boldsymbol{e})+\boldsymbol{F} \Delta \boldsymbol{x}_{c}+\boldsymbol{E} \Delta \boldsymbol{x}_{p}\right\|^{2}\label{Tukey_Cost_Function}
\end{equation}

Where $c$ represents the parameter for Tukey's biweight robust loss function. Several experiments will be conducted on different values of $c$ to determine the most suitable value for the indoor environment. 